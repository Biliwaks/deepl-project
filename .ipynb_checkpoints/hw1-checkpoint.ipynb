{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlc_practical_prologue as prologue\n",
    "import torch\n",
    "from torch import  nn\n",
    "from torch.nn import functional as F\n",
    "import math\n",
    "from torch import optim\n",
    "from torch import Tensor\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input, train_target, train_classes, test_input, test_target, test_classes = prologue.generate_pair_sets(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 196\n",
    "NUM_CLASSES = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_1 = train_input[:, 0, :, :]\n",
    "train_input_2 = train_input[:, 1, :, :]\n",
    "test_input_1 = test_input[:, 0, :, :]\n",
    "test_input_2 = test_input[:, 1, :, :]\n",
    "train_classes_1 = train_classes[:, 0]\n",
    "train_classes_2 = train_classes[:, 1]\n",
    "test_classes_1 = test_classes[:, 0]\n",
    "test_classes_2 = test_classes[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShallowFullyConncectedNet(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(ShallowFullyConncectedNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(IMAGE_SIZE, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, NUM_CLASSES)\n",
    "        self.name = f\"ShallowFullyConncectedNet({nb_hidden})\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x.view(-1, IMAGE_SIZE)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFullyConncectedNet(nn.Module):\n",
    "    def __init__(self, nb_layers):\n",
    "        super(DeepFullyConncectedNet, self).__init__()\n",
    "        self.layers = nn.ModuleList([])\n",
    "        self.name = f\"DeepFullyConncectedNet({nb_layers})\"\n",
    "        acc = IMAGE_SIZE\n",
    "        if nb_layers % 2 !=0:\n",
    "            nb_layers = nb_layers - 1\n",
    "        for l in range(nb_layers):\n",
    "            if l < nb_layers/2:\n",
    "                self.layers.append(nn.Linear(acc, acc*2))\n",
    "                acc = acc*2\n",
    "            else:\n",
    "                self.layers.append(nn.Linear(acc, int(acc/2)))\n",
    "                acc = int(acc/2)\n",
    "        self.layers.append(nn.Linear(IMAGE_SIZE, 10))\n",
    "\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        acc = IMAGE_SIZE\n",
    "        for l in range(len(self.layers)-1):\n",
    "            x = F.relu(self.layers[l](x.view(-1, acc)))\n",
    "            if l < (len(self.layers)-1)/2:\n",
    "                acc = acc*2\n",
    "            else:\n",
    "                acc = int(acc/2)\n",
    "        x = self.layers[len(self.layers)-1](x)\n",
    "\n",
    "       \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, nb_hidden):\n",
    "        super(BasicCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(256, nb_hidden)\n",
    "        self.fc2 = nn.Linear(nb_hidden, 10)\n",
    "        self.name = f\"BasicCNN({nb_hidden})\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x.view(-1, 1, 14, 14)), kernel_size=2, stride=2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), kernel_size=2, stride=2))\n",
    "        x = F.relu(self.fc1(x.view(-1, 256)))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# class ResNetBlock(nn.Module):\n",
    "#     def __init__(self, nb_channels, kernel_size,\n",
    "#                  skip_connections = True, batch_normalization = True):\n",
    "#         super(ResNetBlock, self).__init__()\n",
    "\n",
    "#         self.conv1 = nn.Conv2d(nb_channels, nb_channels,\n",
    "#                                kernel_size = kernel_size,\n",
    "#                                padding = (kernel_size - 1) // 2)\n",
    "\n",
    "#         self.bn1 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "#         self.conv2 = nn.Conv2d(nb_channels, nb_channels,\n",
    "#                                kernel_size = kernel_size,\n",
    "#                                padding = (kernel_size - 1) // 2)\n",
    "\n",
    "#         self.bn2 = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "#         self.skip_connections = skip_connections\n",
    "#         self.batch_normalization = batch_normalization\n",
    "        \n",
    "\n",
    "#     def forward(self, x):\n",
    "#         y = self.conv1(x)\n",
    "#         if self.batch_normalization: y = self.bn1(y)\n",
    "#         y = F.relu(y)\n",
    "#         y = self.conv2(y)\n",
    "#         if self.batch_normalization: y = self.bn2(y)\n",
    "#         if self.skip_connections: y = y + x\n",
    "#         y = F.relu(y)\n",
    "\n",
    "#         return y\n",
    "    \n",
    "\n",
    "# class ResNet(nn.Module):\n",
    "\n",
    "#     def __init__(self, nb_residual_blocks, nb_channels,\n",
    "#                  kernel_size = 3, nb_classes = 10,\n",
    "#                  skip_connections = True, batch_normalization = True):\n",
    "#         super(ResNet, self).__init__()\n",
    "\n",
    "#         self.conv = nn.Conv2d(3, nb_channels,\n",
    "#                               kernel_size = kernel_size,\n",
    "#                               padding = (kernel_size - 1) // 2)\n",
    "#         self.bn = nn.BatchNorm2d(nb_channels)\n",
    "\n",
    "#         self.resnet_blocks = nn.Sequential(\n",
    "#             *(ResNetBlock(nb_channels, kernel_size, skip_connections, batch_normalization)\n",
    "#               for _ in range(nb_residual_blocks))\n",
    "#         )\n",
    "\n",
    "#         self.fc = nn.Linear(nb_channels, nb_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = F.relu(self.bn(self.conv(x)))\n",
    "#         x = self.resnet_blocks(x)\n",
    "#         x = F.avg_pool2d(x, 32).view(x.size(0), -1)\n",
    "#         x = self.fc(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_input, train_target, mini_batch_size, eta, criterion = nn.CrossEntropyLoss(), nb_epochs = 25):\n",
    "    accuracy = []\n",
    "    optimizer = optim.SGD(model.parameters(), eta)\n",
    "    running_loss = 0.0\n",
    "    for e in range(nb_epochs):\n",
    "        for b in range(0, train_input.size(0), mini_batch_size):\n",
    "            output = model(train_input.narrow(0, b, mini_batch_size))\n",
    "            loss = criterion(output, train_target.narrow(0, b, mini_batch_size))\n",
    "            model.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "        # print loss statistics\n",
    "        print('[%d] loss: %.3f' %\n",
    "              (e + 1, running_loss / mini_batch_size))\n",
    "        running_loss = 0.0\n",
    "        \n",
    "        # compute accuracy\n",
    "        accuracy.append(compute_digit_accuracy(model, train_input, train_target, mini_batch_size))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_digit_accuracy(model, input, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "    for b in range(0, input.size(0), mini_batch_size):\n",
    "        output = model(input.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes = output.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k] != predicted_classes[k]:\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors / target.size(0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_project_accuracy(model, input1, input2, target, mini_batch_size):\n",
    "    nb_errors = 0\n",
    "    for b in range(0, input1.size(0), mini_batch_size):\n",
    "        output1 = model(input1.narrow(0, b, mini_batch_size))\n",
    "        output2 = model(input2.narrow(0, b, mini_batch_size))\n",
    "        _, predicted_classes1 = output1.max(1)\n",
    "        _, predicted_classes2 = output2.max(1)\n",
    "        for k in range(mini_batch_size):\n",
    "            if target[b + k] != (predicted_classes1[k] <= predicted_classes2[k]):\n",
    "                nb_errors = nb_errors + 1\n",
    "\n",
    "    return nb_errors / target.size(0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test(model, mini_batch_size, eta, criterion, nb_epochs):\n",
    "    train = torch.cat((train_input_1, train_input_2), 0)\n",
    "    target = torch.cat((train_classes_1, train_classes_2), 0)\n",
    "\n",
    "    accuracy = train_model(model, train, target, mini_batch_size, eta, criterion, nb_epochs)\n",
    "    train_error = compute_project_accuracy(model, train_input_1, train_input_2, train_target, mini_batch_size) \n",
    "    test_error = compute_project_accuracy(model, test_input_1, test_input_2, test_target, mini_batch_size) / target.size(0) * 100\n",
    "    print(f'MODEL: {model.name}, BATCH_SIZE: { mini_batch_size}, CRITERION: {str(criterion)}, EPOCHS: {nb_epochs}, train_error:{train_error}%, test_error: {test_error}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2887.007\n",
      "MODEL: ShallowFullyConncectedNet(1000), BATCH_SIZE: 100, CRITERION: CrossEntropyLoss(), EPOCHS: 25, train_error:43.9%, test_error: 2.355%\n"
     ]
    }
   ],
   "source": [
    "train_test(ShallowFullyConncectedNet(1000), mini_batch_size=100, eta = 1e-1, criterion =nn.CrossEntropyLoss(), nb_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-0d460b0c6745>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'accuracy' is not defined"
     ]
    }
   ],
   "source": [
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 0.446\n",
      "[2] loss: 0.430\n",
      "[3] loss: 0.369\n",
      "[4] loss: 0.316\n",
      "[5] loss: 0.191\n",
      "[6] loss: 0.121\n",
      "[7] loss: 0.083\n",
      "[8] loss: 0.062\n",
      "[9] loss: 0.043\n",
      "[10] loss: 0.113\n",
      "[11] loss: 0.060\n",
      "[12] loss: 0.017\n",
      "[13] loss: 0.009\n",
      "[14] loss: 0.006\n",
      "[15] loss: 0.003\n",
      "[16] loss: 0.002\n",
      "[17] loss: 0.002\n",
      "[18] loss: 0.001\n",
      "[19] loss: 0.001\n",
      "[20] loss: 0.001\n",
      "[21] loss: 0.001\n",
      "[22] loss: 0.000\n",
      "[23] loss: 0.000\n",
      "[24] loss: 0.000\n",
      "[25] loss: 0.000\n",
      "MODEL: DeepFullyConncectedNet(7), BATCH_SIZE: 100, CRITERION: CrossEntropyLoss(), EPOCHS: 25, train_error:0.0%, test_error: 3.8%\n"
     ]
    }
   ],
   "source": [
    "train_test(DeepFullyConncectedNet(7), 100, eta = 1e-1, criterion =nn.CrossEntropyLoss(), nb_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 2397556.622\n",
      "[2] loss: 0.461\n",
      "[3] loss: 0.460\n",
      "[4] loss: 0.460\n",
      "[5] loss: 0.460\n",
      "[6] loss: 0.460\n",
      "[7] loss: 0.460\n",
      "[8] loss: 0.460\n",
      "[9] loss: 0.460\n",
      "[10] loss: 0.460\n",
      "[11] loss: 0.460\n",
      "[12] loss: 0.460\n",
      "[13] loss: 0.460\n",
      "[14] loss: 0.460\n",
      "[15] loss: 0.460\n",
      "[16] loss: 0.460\n",
      "[17] loss: 0.460\n",
      "[18] loss: 0.460\n",
      "[19] loss: 0.460\n",
      "[20] loss: 0.460\n",
      "[21] loss: 0.460\n",
      "[22] loss: 0.460\n",
      "[23] loss: 0.460\n",
      "[24] loss: 0.460\n",
      "[25] loss: 0.460\n",
      "MODEL: BasicCNN(100), BATCH_SIZE: 100, CRITERION: CrossEntropyLoss(), EPOCHS: 25, train_error:45.2%, test_error: 47.599999999999994%\n"
     ]
    }
   ],
   "source": [
    "train_test(BasicCNN(100), 100, eta = 1e-1, criterion =nn.CrossEntropyLoss(), nb_epochs = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BasicCNN(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=256, out_features=100, bias=True)\n",
       "  (fc2): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BasicCNN(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 1, 14, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_input_1.view(-1, 1, 14, 14).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeepFullyConncectedNet(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=196, out_features=392, bias=True)\n",
       "    (1): Linear(in_features=392, out_features=784, bias=True)\n",
       "    (2): Linear(in_features=784, out_features=1568, bias=True)\n",
       "    (3): Linear(in_features=1568, out_features=784, bias=True)\n",
       "    (4): Linear(in_features=784, out_features=392, bias=True)\n",
       "    (5): Linear(in_features=392, out_features=196, bias=True)\n",
       "    (6): Linear(in_features=196, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DeepFullyConncectedNet(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
